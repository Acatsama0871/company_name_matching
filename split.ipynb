{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from typing import List, Dict\n",
    "from dask.diagnostics import ProgressBar\n",
    "ProgressBar().register()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace_dict = {'bank corporation': 'bank', 'bank corporate': 'bank', 'bank corp': 'bank'}\n",
    "\n",
    "# test_names = ['ORIX Bank Corporation', 'LLOYDS BANK CORPORATE MARKETS PLC', 'Trustco Bank Corp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import List, Dict\n",
    "\n",
    "# to_remove_words_list = [\n",
    "#     \"inc\",\n",
    "#     \"inc.\",\n",
    "#     \"incorporated\",\n",
    "#     \"llc\",\n",
    "#     \"l.l.c.\",\n",
    "#     \"l.l.c\",\n",
    "#     \"co.\",\n",
    "#     \"securities\",\n",
    "#     \"security\",\n",
    "#     \"s.a.\",\n",
    "#     \"s.a\",\n",
    "#     \"l.p.\",\n",
    "#     \"plc\",\n",
    "#     \"ag\",\n",
    "#     \"s.a.s\",\n",
    "#     \"s.a.s.\",\n",
    "#     \"s.p.a.\",\n",
    "#     \"s.p.a\",\n",
    "#     \"sa\",\n",
    "#     \"ab\",\n",
    "#     \"trust\",\n",
    "#     \"limited\",\n",
    "#     \"ltd\",\n",
    "#     \"ltd.\",\n",
    "# ]\n",
    "\n",
    "# replace_dict = {'bank corporation': 'bank', 'bank corporate': 'bank', 'bank corp': 'bank'}\n",
    "\n",
    "# def preprocess(cur_txt: str, to_remove_words_list: List=to_remove_words_list, replace_dict: Dict=replace_dict) -> str:\n",
    "#     \"\"\"\n",
    "#     Preprocess names before matching:\n",
    "#     1. remove commas\n",
    "#     2. replace by name\n",
    "#     3. remove words in to_remove_words_list\n",
    "\n",
    "#     Args:\n",
    "#         cur_txt (str): current name\n",
    "#         to_remove_words_list (List[srt]): list of words to remove\n",
    "\n",
    "#     Returns:\n",
    "#         str: preprocessed equity name\n",
    "#     \"\"\"\n",
    "#     #* 0. lower the name\n",
    "#     cur_txt = cur_txt.lower()\n",
    "#     #* 1. replace comma\n",
    "#     cur_txt = cur_txt.replace(\",\", \"\")\n",
    "#     #* 2. replace by name\n",
    "#     for cur_key in replace_dict:\n",
    "#         if cur_key in cur_txt:\n",
    "#             cur_txt = cur_txt.replace(cur_key, replace_dict[cur_key])\n",
    "#             break\n",
    "#     #* 3. remove words in to_remove_words_list\n",
    "#     cur_txt = cur_txt.split(\" \")\n",
    "#     result_str_list = [\n",
    "#         cur_word\n",
    "#         for cur_word in cur_txt\n",
    "#         if cur_word not in to_remove_words_list\n",
    "#     ]\n",
    "\n",
    "#     return \" \".join(result_str_list).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trustco bank'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess(test_names[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full Name</th>\n",
       "      <th>No.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 MAJ Metalska</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 MAJ Zavrsni Rad Gradjevinarstvu</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1300 Smiles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 Park Street Trust</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25 Novembar Celinac</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Full Name  No. \n",
       "0                     1 MAJ Metalska     1\n",
       "1  1 MAJ Zavrsni Rad Gradjevinarstvu     2\n",
       "2                        1300 Smiles     3\n",
       "3                2 Park Street Trust     4\n",
       "4                25 Novembar Celinac     5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search df\n",
    "search_df = pd.read_excel(os.path.join('data', '01_raw', 'search_df.xlsx'))\n",
    "search_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_df.to_csv(os.path.join('data', '02_primary', 'search.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target Name</th>\n",
       "      <th>Target No.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3I Group PLC</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3I INFRASTRUCTURE PLC</td>\n",
       "      <td>12378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4finance S.A.</td>\n",
       "      <td>15299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50Hertz Transmission GmbH</td>\n",
       "      <td>7693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6PM HOLDINGS P.L.C.</td>\n",
       "      <td>15484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Target Name  Target No.\n",
       "0               3I Group PLC         190\n",
       "1      3I INFRASTRUCTURE PLC       12378\n",
       "2              4finance S.A.       15299\n",
       "3  50Hertz Transmission GmbH        7693\n",
       "4        6PM HOLDINGS P.L.C.       15484"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target df\n",
    "target_df = pd.read_excel(os.path.join('data', '01_raw', 'target_df.xlsx'))\n",
    "target_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df.to_csv(os.path.join('data', '02_primary', 'target.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8270, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Target Name', 'Target No.'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Target Df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8270, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target Name</th>\n",
       "      <th>Target No.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=100</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>object</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8217</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8269</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: from_pandas, 100 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                Target Name Target No.\n",
       "npartitions=100                       \n",
       "0                    object      int64\n",
       "83                      ...        ...\n",
       "...                     ...        ...\n",
       "8217                    ...        ...\n",
       "8269                    ...        ...\n",
       "Dask Name: from_pandas, 100 tasks"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df = pd.read_csv(\"data/02_primary/target.csv\")\n",
    "print(target_df.shape)\n",
    "target_df = dd.from_pandas(target_df, npartitions=100)\n",
    "target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/research/haohang/text_matching/data/04_splits/00.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/01.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/02.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/03.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/04.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/05.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/06.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/07.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/08.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/09.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/10.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/11.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/12.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/13.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/14.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/15.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/16.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/17.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/18.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/19.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/20.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/21.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/22.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/23.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/24.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/25.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/26.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/27.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/28.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/29.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/30.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/31.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/32.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/33.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/34.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/35.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/36.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/37.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/38.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/39.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/40.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/41.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/42.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/43.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/44.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/45.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/46.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/47.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/48.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/49.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/50.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/51.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/52.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/53.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/54.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/55.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/56.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/57.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/58.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/59.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/60.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/61.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/62.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/63.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/64.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/65.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/66.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/67.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/68.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/69.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/70.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/71.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/72.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/73.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/74.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/75.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/76.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/77.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/78.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/79.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/80.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/81.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/82.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/83.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/84.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/85.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/86.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/87.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/88.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/89.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/90.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/91.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/92.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/93.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/94.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/95.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/96.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/97.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/98.csv',\n",
       " '/research/haohang/text_matching/data/04_splits/99.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df.to_csv('data/04_splits/*.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Search df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(317751, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_df = pd.read_csv(os.path.join('data', '02_primary', 'search.csv'))\n",
    "search_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove_words_list = [\n",
    "    \"inc\",\n",
    "    \"inc.\",\n",
    "    \"incorporated\",\n",
    "    \"llc\",\n",
    "    \"l.l.c.\",\n",
    "    \"l.l.c\",\n",
    "    \"co.\",\n",
    "    \"securities\",\n",
    "    \"security\",\n",
    "    \"s.a.\",\n",
    "    \"s.a\",\n",
    "    \"l.p.\",\n",
    "    \"plc\",\n",
    "    \"ag\",\n",
    "    \"s.a.s\",\n",
    "    \"s.a.s.\",\n",
    "    \"s.p.a.\",\n",
    "    \"s.p.a\",\n",
    "    \"sa\",\n",
    "    \"ab\",\n",
    "    \"trust\",\n",
    "    \"limited\",\n",
    "    \"ltd\",\n",
    "    \"ltd.\",\n",
    "]\n",
    "\n",
    "replace_dict = {'bank corporation': 'bank', 'bank corporate': 'bank', 'bank corp': 'bank'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(cur_txt: str, to_remove_words_list: List=to_remove_words_list, replace_dict: Dict=replace_dict) -> str:\n",
    "    \"\"\"\n",
    "    Preprocess names before matching:\n",
    "    1. remove commas\n",
    "    2. replace by name\n",
    "    3. remove words in to_remove_words_list\n",
    "\n",
    "    Args:\n",
    "        cur_txt (str): current name\n",
    "        to_remove_words_list (List[srt]): list of words to remove\n",
    "\n",
    "    Returns:\n",
    "        str: preprocessed equity name\n",
    "    \"\"\"\n",
    "    #* 0. lower the name\n",
    "    cur_txt = cur_txt.lower()\n",
    "    #* 1. replace comma\n",
    "    cur_txt = cur_txt.replace(\",\", \"\")\n",
    "    #* 2. replace by name\n",
    "    for cur_key in replace_dict:\n",
    "        if cur_key in cur_txt:\n",
    "            cur_txt = cur_txt.replace(cur_key, replace_dict[cur_key])\n",
    "            break\n",
    "    #* 3. remove words in to_remove_words_list\n",
    "    cur_txt = cur_txt.split(\" \")\n",
    "    result_str_list = [\n",
    "        cur_word\n",
    "        for cur_word in cur_txt\n",
    "        if cur_word not in to_remove_words_list\n",
    "    ]\n",
    "\n",
    "    return \" \".join(result_str_list).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_df['preprocessed'] = search_df['Full Name'].apply(preprocess)\n",
    "with open(os.path.join('data', '03_feature', 'search_df.pkl'), 'wb') as f:\n",
    "    pickle.dump(search_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_df['preprocessed'] = search_df['Full Name'].apply(preprocess)\n",
    "# search_list = search_df['preprocessed'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_df_preprocessed2full_name = {cur_row['preprocessed']: cur_row['Full Name'] for _, cur_row in search_df.iterrows()}\n",
    "# search_df_full_name2id = {cur_row['Full Name']: cur_row['No. '] for _, cur_row in search_df.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save as pickle\n",
    "# with open(os.path.join('data', '03_feature', 'search_list.pkl'), 'wb') as f:\n",
    "#     pickle.dump(search_list, f)\n",
    "# with open(os.path.join('data', '03_feature', 'search_df_preprocessed2full_name.pkl'), 'wb') as f:\n",
    "#     pickle.dump(search_df_preprocessed2full_name, f)\n",
    "# with open(os.path.join('data', '03_feature', 'search_df_full_name2id.pkl'), 'wb') as f:\n",
    "#     pickle.dump(search_df_full_name2id, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea57f8ffba09633efa022ea1e2936fe77dafc7af9e2fff9c325ddf7d60cd6a04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
